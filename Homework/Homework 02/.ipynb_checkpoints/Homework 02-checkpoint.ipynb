{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adan Constanzo- Homework 02\n",
    "# CS 4661"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required packages and libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A:\n",
    "#### Reading the iris dataset from url\n",
    "\n",
    "reads a csv file from the web and stores it in a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris_df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting \"catergorical\" labels to \"numerical\" labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def categorical_to_numeric(x):\n",
    "    if x == 'setosa':\n",
    "        return 0\n",
    "    elif x == 'versicolor':\n",
    "        return 1\n",
    "    elif x == 'virginica':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['label'] = iris_df['species'].apply(categorical_to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Feature Matrix and Label Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "X = iris_df[feature_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a Series of labels from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris_df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B:\n",
    "#### Splitting testing and training sets with paramaters test_size = 0.4, random_state=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C:\n",
    "#### Instantiating a KNN object with k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D:\n",
    "#### Repeating part c for K=1, K=5, K=7, K=11, K=15, K=27, K=59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.95, 5: 0.9833333333333333, 7: 0.9666666666666667, 11: 0.9666666666666667, 15: 0.9333333333333333, 27: 0.9166666666666666, 59: 0.8166666666666667}\n"
     ]
    }
   ],
   "source": [
    "loops = [1, 5, 7, 11, 15, 27, 59]\n",
    "accuracy = {}\n",
    "for x in loops:\n",
    "    knn = KNeighborsClassifier(n_neighbors=x)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    accuracy[x] = accuracy_score(y_test, y_predict)\n",
    "    \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not get better by increasing neighboors K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E:\n",
    "#### Making predictions with only ONE single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sepal_length': 0.7166666666666667, 'sepal_width': 0.5666666666666667, 'petal_length': 0.9333333333333333, 'petal_width': 0.95}\n"
     ]
    }
   ],
   "source": [
    "accuracy_one_feature = {}\n",
    "\n",
    "X = iris_df[feature_cols]\n",
    "y = iris_df['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=6)\n",
    "\n",
    "for i in feature_cols:\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    x_train = [ [x] for x in X_train[i] ]\n",
    "    knn.fit(x_train, y_train)\n",
    "    x_test = [ [x] for x in X_test[i] ]\n",
    "    y_predict = knn.predict(x_test)\n",
    "    accuracy_one_feature[i] = accuracy_score(y_test, y_predict)\n",
    "print(accuracy_one_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Single Feature to compare with is petal_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F:\n",
    "#### Repeating E with two features and making predictions on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('sepal_length', 'sepal_width'): 0.8166666666666667, ('sepal_length', 'petal_length'): 0.9833333333333333, ('sepal_length', 'petal_width'): 0.95, ('sepal_width', 'petal_length'): 0.95, ('sepal_width', 'petal_width'): 0.95, ('petal_length', 'petal_width'): 0.9666666666666667}\n"
     ]
    }
   ],
   "source": [
    "two_features = [(0,1), (0,2), (0,3), (1,2), (1,3), (2,3)]\n",
    "two_features_col = [(feature_cols[x], feature_cols[y]) for x,y in two_features]\n",
    "accuracy_two_feature = {}\n",
    "\n",
    "for i,j in two_features_col:\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    x_train = list(zip([ x for x in X_train[i] ],[ x for x in X_train[j] ]))\n",
    "    knn.fit(x_train, y_train)\n",
    "    x_test = list(zip([ x for x in X_test[i] ], [ x for x in X_test[j] ]))\n",
    "    y_predict = knn.predict(x_test)\n",
    "    accuracy_two_feature[i,j] = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(accuracy_two_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best two features are sepal_length and petal_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G:\n",
    "Does the “best feature pair” from part (f) contain of both “first best feature”\n",
    "and “second best feature” from part (e)? In other word, can we conclude that the “best\n",
    "two features” for classification are the first best feature along with the second best feature\n",
    "together?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The top two features from E were petal_length and petal_width, the best two features from F were sepal_length and petal_length, therefore, they do not conclude to be the best two features for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H\n",
    "Optional Question: Justify your answer for part (g)! If yes, why? If no, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### They do not conclude the two best features because they probably share similarities between one another. Using these different features allows variety in the data and allows KNN classification to outcome a better accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
